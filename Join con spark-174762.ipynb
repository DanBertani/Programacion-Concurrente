{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UQAJS17EEaI"
   },
   "source": [
    "### Programación Concurrente\n",
    "## 27. Joins con Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0dtuuRww-ekh"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, to_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "X2lSnbMu90R9",
    "outputId": "54f882e3-8639-4500-8a9d-86d859e223b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-G8N1ISA:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x18ec81ef310>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2haTcTjDZPa"
   },
   "source": [
    "Un Join es una operación que permite combinar datos de dos o más tablas en una sola, basándose en una relación entre ellas. Usualmente, esta relación se establece a través de una columna en común entre las tablas.\n",
    "\n",
    "El Join permite acceder y manipular datos que están distribuidos en varias tablas de manera conjunta, obteniendo así resultados más complejos y completos.\n",
    "\n",
    "Vamos a leer tres tablas; estas se encuentran en este [enlace de Kaggle](https://www.kaggle.com/datasets/svbstan/sales-product-and-customer-insight-repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QT5siaoqDq1V",
    "outputId": "82a3ae56-17d1-458c-a7e6-344735a3ca80",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-------------------+--------------------+------------+-------------------+-------------+-----------+-----+--------+\n",
      "|customer_id|first_name|last_name|gender|      date_of_birth|               email|phone_number|        signup_date|      address|       city|state|zip_code|\n",
      "+-----------+----------+---------+------+-------------------+--------------------+------------+-------------------+-------------+-----------+-----+--------+\n",
      "|          1|    Robert|    Smith|Female|1994-06-14 21:40:27|jane.davis1@mail.com|634-106-4981|2016-10-16 17:23:25| 8465 Main St|San Antonio|   CA|   35566|\n",
      "|          2|     Emily|   Garcia|Female|1989-09-21 17:56:31|robert.williams2@...|386-635-5998|2021-04-04 14:24:06|  305 Main St|   New York|   AZ|   23187|\n",
      "|          3|   Jessica|    Brown|  Male|1984-01-21 21:43:13|emily.davis3@mail...|627-341-5213|2018-04-22 04:51:57|  5725 Oak St|    Chicago|   AZ|   99188|\n",
      "|          4|   Michael|    Brown|  Male|1986-02-06 13:09:53|jessica.williams4...|126-662-8981|2018-07-06 17:45:14|  8468 Oak St|Los Angeles|   TX|   77421|\n",
      "|          5|    Robert|    Jones|  Male|1996-12-05 05:10:11|robert.martinez5@...|758-947-2802|2018-03-11 01:43:10|2820 Maple St|    Chicago|   TX|   36281|\n",
      "+-----------+----------+---------+------+-------------------+--------------------+------------+-------------------+-------------+-----------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer = spark.read.csv('customer_profile_dataset.csv', header=True)\n",
    "customer.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2siPRUfFWOH",
    "outputId": "f85148e2-0169-418a-9885-740707e08b81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------+--------------+------+--------------------+\n",
      "|product_id|product_name|category|price_per_unit| brand| product_description|\n",
      "+----------+------------+--------+--------------+------+--------------------+\n",
      "|         1|      Butter|   Dairy|         28.58|BrandB|Description for Rice|\n",
      "|         2|      Butter|   Meats|         22.66|BrandB|Description for B...|\n",
      "|         3|        Milk|   Meats|         26.52|BrandE|Description for B...|\n",
      "|         4|      Banana|  Grains|         26.12|BrandB|Description for A...|\n",
      "|         5|        Rice|  Fruits|         21.94|BrandD|Description for B...|\n",
      "+----------+------------+--------+--------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products = spark.read.csv('products_dataset.csv', header=True)\n",
    "products.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UMpzJfv5F8fz",
    "outputId": "37a75004-4d06-4beb-ed5c-e2e6eeb6a018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+----------+-------------------+--------+------------------+\n",
      "|purchase_id|customer_id|product_id|      purchase_date|quantity|      total_amount|\n",
      "+-----------+-----------+----------+-------------------+--------+------------------+\n",
      "|          1|          1|        42|2018-04-15 14:08:01|       3| 37.64207365077783|\n",
      "|          2|          1|       138|2022-07-10 23:33:47|       4| 70.24710587172727|\n",
      "|          3|          1|       403|2021-12-31 03:53:33|       3| 89.16889585975464|\n",
      "|          4|          1|       193|2017-01-14 01:25:11|       2| 59.70505931112876|\n",
      "|          5|          1|        26|2018-04-06 11:01:06|       3|101.77886387225126|\n",
      "+-----------+-----------+----------+-------------------+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchase = spark.read.csv('purchase_history_dataset.csv', header=True)\n",
    "purchase.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NE8CLqxoOGip"
   },
   "source": [
    "Ejercicios; contesta desarrollando el correspondiente código en Pyspark:\n",
    "\n",
    "1. Responde, ¿cuántos clientes llamados \"Robert\" (nota cómo hay *Males* y *Females*), compraron algún producto lácteo (Dairy) en 2022 ?\n",
    "\n",
    "2. Eres empleado de *BrandB*. ¿En cuáles ciudades has vendido una mayor cantidad? (total_amount)\n",
    "\n",
    "3. ¿De cuánto es la mayor cantidad (quantity) que ha sido comprado por algún hombre O cuyo producto sea pan (Bread)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "P_a5y8AFOEjC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de clientes llamados Robert que compraron productos lácteos en 2022: 44\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, year\n",
    "\n",
    "# Combinar todo en una sola indicación\n",
    "robert_count = purchase.filter(year(col(\"purchase_date\")) == 2022) \\\n",
    "    .join(products.filter(col(\"category\") == \"Dairy\"), \"product_id\") \\\n",
    "    .join(customer.filter(col(\"first_name\") == \"Robert\"), \"customer_id\") \\\n",
    "    .select(\"customer_id\").count()\n",
    "\n",
    "##Se cuentan todos los roberts aunque este sean repetidos \n",
    "print(f\"Cantidad de clientes llamados Robert que compraron productos lácteos en 2022: {robert_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La ciudad con la mayor cantidad vendida de BrandB es Chicago con un total de 29557.642903425036.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Convertir \"total_amount\" a tipo Double\n",
    "purchase = purchase.withColumn(\"total_amount\", col(\"total_amount\").cast(DoubleType()))\n",
    "\n",
    "# Filtrar productos por la marca, unir con compras y clientes, agrupar por ciudad, y calcular total_amount\n",
    "top_city = (\n",
    "    purchase.join(products.filter(col(\"brand\") == \"BrandB\"), \"product_id\")\n",
    "    .join(customer, \"customer_id\")\n",
    "    .groupBy(\"city\")\n",
    "    .sum(\"total_amount\")\n",
    "    .withColumnRenamed(\"sum(total_amount)\", \"total_amount\")\n",
    "    .orderBy(col(\"total_amount\").desc())\n",
    "    .first()\n",
    ")\n",
    "\n",
    "# Resultado\n",
    "print(f\"La ciudad con la mayor cantidad vendida de BrandB es {top_city['city']} con un total de {top_city['total_amount']}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mayor cantidad comprada por un hombre o de productos Bread es: 5.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, max as spark_max\n",
    "\n",
    "# Filtrar compras realizadas por hombres o productos tipo Bread, y calcular la cantidad máxima\n",
    "max_quantity = (\n",
    "    purchase.join(customer, \"customer_id\")\n",
    "            .join(products, \"product_id\")\n",
    "            .filter((col(\"gender\") == \"Male\") | (col(\"product_name\") == \"Bread\"))\n",
    "            .agg(spark_max(\"quantity\").alias(\"max_quantity\"))\n",
    "            .collect()[0][\"max_quantity\"]\n",
    ")\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(f\"La mayor cantidad comprada por un hombre o de productos Bread es: {max_quantity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
